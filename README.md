LUMIRA â€” AI Project Expo Assistant

LUMIRA is your smart, context-aware AI-powered project assistant.
Give it a PDF â†’ It studies it â†’ Vectorizes your content â†’ Answers expo questions like a pro.
Zero hallucinations. Zero confusion. Pure contextual accuracy.

ğŸš€ What Lumira Does

ğŸ“„ Reads & extracts your project PDF

ğŸ§  Breaks it into clean sections

ğŸ” Converts it into vector embeddings using mxbai-embed-large

ğŸ—‚ Stores everything inside ChromaDB

ğŸ¤– Answers questions using Llama 3.2 with context-only responses

ğŸ¤ Perfect for project expos, viva, presentations & documentation

ğŸ§© Tech Stack

Python

LangChain

Ollama (Llama 3.2)

Chroma Vector DB

mxbai-embed-large embeddings

PyPDFLoader for PDF parsing

ğŸ“‚ Folder Structure
/Lumira
â”‚â”€â”€ Dataset/
â”‚   â””â”€â”€ InfoBotDataset.pdf
â”‚â”€â”€ Database/
â”‚â”€â”€ Utils/
â”‚   â””â”€â”€ pdfvectorising.py
â”‚â”€â”€ bot.py
â”‚â”€â”€ README.md

âš™ï¸ How It Works
1ï¸âƒ£ Vectorizer â€” pdfvectorising.py

Loads the PDF

Extracts sections (Executive Summary, Intro, Methodology, etc.)

Embeds the cleaned content

Saves everything to ChromaDB

2ï¸âƒ£ Bot â€” bot.py

Loads your vector store

Retrieves context relevant to your question

Feeds it to Llama 3.2

Responds only based on your project PDF

â–¶ï¸ Quick Start
Install dependencies
pip install langchain-community langchain-chroma langchain-ollama chromadb pypdf

Start Ollama
ollama run llama3.2

Create the vector database
python Utils/pdfvectorising.py

Run the bot
python bot.py

ğŸ’¬ Sample Interaction
Ask question: What technologies are used in this project?

â†’ LUMIRA answers based strictly on your PDF data.

ğŸŒŸ Why LUMIRA?

Expo students stop panicking

Answers are crisp and contextual

No hallucinations

Reusable for any project â€” just replace the PDF

Lightweight, local, private

ğŸ“œ License

This project is open-source under MIT.
Feel free to improve it, remix it, or build bigger things on top. ğŸ’š
